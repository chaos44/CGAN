{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3BjhbCI1SzEU1uSD0DbVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaos44/CGAN/blob/master/pokemon_gray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbaLrq5OeWPL"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.compat.v1.keras.layers import BatchNormalization\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import (Activation, Concatenate, Dense,\n",
        "                          Embedding, Fl   atten, Input, Multiply, Reshape)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPPENm6mvmy"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)#2. Get the file\n",
        "pokemon = drive.CreateFile({'id':'1E41YoGi2qBFsT5wijnPT9xm0Y8BFB1bz'}) # replace the id with id of file you want to access\n",
        "pokemon.GetContentFile('pokemon.zip')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqRPsao7nOcD"
      },
      "source": [
        "!unzip pokemon.zip -d pokemon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebaDL-qbDYsi"
      },
      "source": [
        "# パラメータの初期化\n",
        "classes = {'red' : 0, 'green' : 1, 'blue' : 2, 'bird' : 3, 'combat' : 4, 'dargon' : 5, 'electricity' : 6, 'ghost' : 7, 'insect' : 8, 'normal' : 9\n",
        "         , 'poison' : 10, 'rock' : 11, 'supernatural' : 12, 'ground' : 13, 'ice': 14}"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcboI0cCeed-"
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "#   入力画像の次元\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# 生成器の入力として用いるノイズベクトルのサイズ\n",
        "z_dim = 100\n",
        "\n",
        "# データセットに含まれるクラスの数\n",
        "num_classes = 15"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0wycNQEeiLM"
      },
      "source": [
        "# Generator\n",
        "def build_generator(z_dim):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 入力を、全結合層を通じて7 * 7 * 256のテンソルに変形する\n",
        "    ## Denseは入力をテンソルに変えることもできる、第一層だけ、input_dimを指定する必要がある。(input_dimもテンソル指定できるのか、普通はベクトル単位だと思うが)\n",
        "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
        "    ## Reshapeの意味？\n",
        "    model.add(Reshape((7, 7, 256))) \n",
        "\n",
        "    # 転置畳み込み層 from 7x7x256 into 14x14x128 tensor\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ODHKQpbejxd"
      },
      "source": [
        "def build_cgan_generator(z_dim):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "    print('num_classes')\n",
        "    print(num_classes)\n",
        "    print()\n",
        "    # Conditioning label: integer 0-9 specifying the number G should generate\n",
        "    label = Input(shape=(1, ))\n",
        "    print('z:')\n",
        "    print(z)\n",
        "    print()\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # ラベルをz_dimサイズの密のベクトルに変換する。\n",
        "    # 形状(batch_size, 1, z_dim)の3Dテンソルを作成する\n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
        "    print('3D:')\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    print()\n",
        "    # 3Dテンソルを2Dテンソルに平坦化 (batch_size, z_dim)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print('2D:')\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    print()\n",
        "    # ノイズz(1, z_dim)? と (batch_size, z_dim)要素ごとの積を取る（ラベルの特徴を持つノイズ） \n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    print(joined_representation)\n",
        "    print(joined_representation.shape)\n",
        "    generator = build_generator(z_dim)\n",
        "\n",
        "    # 与えられたラベルの画像を生成する\n",
        "    conditioned_img = generator(joined_representation)\n",
        "    # [z, label]も返す意味は？\n",
        "    return Model([z, label], conditioned_img)"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFmXUEXMm8KC",
        "outputId": "4f968fc7-85f0-4909-f01d-638656d43bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "'''\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "X_train = X_train / 127.5 - 1.\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "# idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "idx = 0\n",
        "imgs, labels = X_train[idx], y_train[idx]\n",
        "\n",
        "print('idx:')\n",
        "print(idx)\n",
        "print()\n",
        "print('imgs:')\n",
        "print(imgs)\n",
        "print()\n",
        "print('labels:')\n",
        "print(labels)\n",
        "print()\n",
        "\n",
        "batch_size = 32\n",
        "generator = build_cgan_generator(z_dim)\n",
        "z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "gen_imgs = generator.predict([z, labels])\n",
        "print(gen_imgs)\n",
        "'''"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n(X_train, y_train), (_, _) = mnist.load_data()\\n\\n# Rescale [0, 255] grayscale pixel values to [-1, 1]\\nX_train = X_train / 127.5 - 1.\\nX_train = np.expand_dims(X_train, axis=3)\\n# idx = np.random.randint(0, X_train.shape[0], batch_size)\\nidx = 0\\nimgs, labels = X_train[idx], y_train[idx]\\n\\nprint('idx:')\\nprint(idx)\\nprint()\\nprint('imgs:')\\nprint(imgs)\\nprint()\\nprint('labels:')\\nprint(labels)\\nprint()\\n\\nbatch_size = 32\\ngenerator = build_cgan_generator(z_dim)\\nz = np.random.normal(0, 1, (batch_size, z_dim))\\ngen_imgs = generator.predict([z, labels])\\nprint(gen_imgs)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnL5E1-BemEt"
      },
      "source": [
        "# Discriminator\n",
        "def build_discriminator(img_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layer, from 28x28x2 into 14x14x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 3),\n",
        "               # チャンネル数も加算\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 4),\n",
        "               padding='same'))\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 14x14x64 into 7x7x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
        "    model.add(\n",
        "        Conv2D(128,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Output layer with sigmoid activation\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6tErBu-z2Cr"
      },
      "source": [
        "# 実験コード\n",
        "# 識別器の複合表現 (画像 + ラベル + 画像 + ラベル) 28 * 28 * 4 "
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMS5kHcpepkY"
      },
      "source": [
        "def build_cgan_discriminator(img_shape):\n",
        "    print(num_classes)\n",
        "    # Input image\n",
        "    img = Input(shape=img_shape)\n",
        "\n",
        "    # Label for the input image\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # Turns labels into dense vectors of size z_dim\n",
        "    # Produces 3D tensor with shape (batch_size, 1, 28*28*1)\n",
        "    label_embedding = Embedding(num_classes,\n",
        "                                np.prod(img_shape),\n",
        "                                input_length=1)(label)\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    # Flatten the embedding 3D tensor into 2D tensor with shape (batch_size, 28*28*1)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    # Reshape label embeddings to have same dimensions as input images\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    print(img.shape)\n",
        "    # Concatenate images with their label embeddings\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    concatenated = Multiply()([img, label_embedding]) # Multiply()使うとshapeは(None, 28, 28, 1)でエラー、(None, 28, 28, 2)だと正しい\n",
        "    # 疑問：なぜconcatenatedは(None, 28, 28, 2)のshapeを持たないといけない？\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    # concatenated = Concatenate(axis=-1)([concatenated_tmp, concatenated_tmp])\n",
        "    print('concatenated:')\n",
        "    print(concatenated)\n",
        "    print(concatenated.shape)\n",
        "    print()\n",
        "    discriminator = build_discriminator(img_shape)\n",
        "\n",
        "    # Classify the image-label pair\n",
        "    classification = discriminator(concatenated)\n",
        "    # classificationは与えられた\n",
        "    return Model([img, label], classification)"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWLSpZJerZ-"
      },
      "source": [
        "# Build the Model\n",
        "def build_cgan(generator, discriminator):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "\n",
        "    # Image label\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Generated image for that label\n",
        "    img = generator([z, label])\n",
        "\n",
        "    classification = discriminator([img, label])\n",
        "\n",
        "    # Combined Generator -> Discriminator model\n",
        "    # G([z, lablel]) = x*\n",
        "    # D(x*) = classification\n",
        "    model = Model([z, label], classification)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV58o3K9esuV",
        "outputId": "bc0358cf-f8bb-4e3b-9944-fab9260deb48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build and compile the Discriminator\n",
        "discriminator = build_cgan_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "discriminator.summary()\n",
        "# Build the Generator\n",
        "generator = build_cgan_generator(z_dim)\n",
        "generator.summary()\n",
        "# Keep Discriminator’s parameters constant for Generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build and compile CGAN model with fixed Discriminator to train the Generator\n",
        "cgan = build_cgan(generator, discriminator)\n",
        "cgan.summary()\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "Tensor(\"embedding_49/embedding_lookup/Identity_1:0\", shape=(None, 1, 784), dtype=float32)\n",
            "(None, 1, 784)\n",
            "Tensor(\"flatten_75/Reshape:0\", shape=(None, 784), dtype=float32)\n",
            "(None, 784)\n",
            "(None, 28, 28, 1)\n",
            "(None, 28, 28, 1)\n",
            "concatenated:\n",
            "Tensor(\"multiply_42/mul:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
            "(None, 28, 28, 1)\n",
            "\n",
            "Model: \"functional_129\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_144 (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_49 (Embedding)        (None, 1, 784)       11760       input_144[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_75 (Flatten)            (None, 784)          0           embedding_49[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_143 (InputLayer)          [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_49 (Reshape)            (None, 28, 28, 1)    0           flatten_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_42 (Multiply)          (None, 28, 28, 1)    0           input_143[0][0]                  \n",
            "                                                                 reshape_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_48 (Sequential)      (None, 1)            114241      multiply_42[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 126,001\n",
            "Trainable params: 125,617\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n",
            "num_classes\n",
            "15\n",
            "\n",
            "z:\n",
            "Tensor(\"input_145:0\", shape=(None, 100), dtype=float32)\n",
            "\n",
            "3D:\n",
            "Tensor(\"embedding_50/embedding_lookup/Identity_1:0\", shape=(None, 1, 100), dtype=float32)\n",
            "(None, 1, 100)\n",
            "\n",
            "2D:\n",
            "Tensor(\"flatten_77/Reshape:0\", shape=(None, 100), dtype=float32)\n",
            "(None, 100)\n",
            "\n",
            "Tensor(\"multiply_43/mul:0\", shape=(None, 100), dtype=float32)\n",
            "(None, 100)\n",
            "Model: \"functional_131\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_146 (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_50 (Embedding)        (None, 1, 100)       1500        input_146[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_145 (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_77 (Flatten)            (None, 100)          0           embedding_50[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "multiply_43 (Multiply)          (None, 100)          0           input_145[0][0]                  \n",
            "                                                                 flatten_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_49 (Sequential)      (None, 28, 28, 1)    1637121     multiply_43[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,638,621\n",
            "Trainable params: 1,638,237\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"functional_133\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_147 (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_148 (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_131 (Functional)     (None, 28, 28, 1)    1638621     input_147[0][0]                  \n",
            "                                                                 input_148[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "functional_129 (Functional)     (None, 1)            126001      functional_131[0][0]             \n",
            "                                                                 input_148[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,764,622\n",
            "Trainable params: 1,638,237\n",
            "Non-trainable params: 126,385\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZTeGuQPRkH"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import re"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLJD98seuO2"
      },
      "source": [
        "# Training\n",
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "\n",
        "    # Load the MNIST dataset\n",
        "    # (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    # 画像の読み込みとnumpy配列への変換\n",
        "    X_train = [] # リスト\n",
        "    y_train = [] # リスト\n",
        "    photos_dir = './pokemon'  \n",
        "    files = glob.glob(photos_dir + '/*.png')\n",
        "    for i, file in enumerate(files):\n",
        "        label = re.search(r'\\/([^\\/]+)_', file).groups()[0]\n",
        "        image = Image.open(file)\n",
        "        image = image.convert('L')\n",
        "        image = image.resize((img_rows, img_cols))\n",
        "        data = np.asarray(image, dtype=np.float32)\n",
        "        X_train.append(data)\n",
        "        y_train.append(classes[label])\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    # X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the Discriminator\n",
        "        # -------------------------\n",
        "\n",
        "        # Get a random batch of real images and their labels\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        # print('test:', labels)\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "        # print('z', z.shape)\n",
        "        # print()\n",
        "        # print('gen_imgs', gen_imgs.shape)\n",
        "        # print()\n",
        "        # print('imgs', imgs.shape)\n",
        "        # print()\n",
        "        # print('labels', labels.shape)\n",
        "        # Train the Discriminator\n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of noise vectors\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "        # Get a batch of random labels\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "\n",
        "        # Train the Generator\n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "\n",
        "        if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            # Output training progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (iteration + 1, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "\n",
        "            # Save losses and accuracies so they can be plotted after training\n",
        "            losses.append((d_loss[0], g_loss))\n",
        "            accuracies.append(100 * d_loss[1])\n",
        "\n",
        "            # Output sample of generated images\n",
        "            sample_images()"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFZPbM6evwH"
      },
      "source": [
        "def sample_images(image_grid_rows=3, image_grid_columns=5):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-15\n",
        "    labels = np.arange(0, 15).reshape(-1, 1)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    gen_imgs = np.clip(gen_imgs * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Digit: %d\" % labels[cnt])\n",
        "            cnt += 1"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R69fobc4exPF",
        "outputId": "d2a4809e-e09f-4866-c17d-87a6af70ccbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# Train the Model and Inspect Training Progres\n",
        "# Note that the 'Discrepancy between trainable weights and collected trainable' warning from Keras is expected. \n",
        "# It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa.\n",
        "\n",
        "# Set hyperparameters\n",
        "iterations = 12000\n",
        "batch_size = 32\n",
        "sample_interval = 1000\n",
        "\n",
        "# Train the CGAN for the specified number of iterations\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 [D loss: 0.000480, acc.: 100.00%] [G loss: 8.110432]\n",
            "2000 [D loss: 0.000429, acc.: 100.00%] [G loss: 10.327023]\n",
            "3000 [D loss: 0.001470, acc.: 100.00%] [G loss: 9.868148]\n",
            "4000 [D loss: 0.002398, acc.: 100.00%] [G loss: 5.193663]\n",
            "5000 [D loss: 0.000849, acc.: 100.00%] [G loss: 15.167121]\n",
            "6000 [D loss: 0.002949, acc.: 100.00%] [G loss: 8.249298]\n",
            "7000 [D loss: 0.000136, acc.: 100.00%] [G loss: 8.391935]\n",
            "8000 [D loss: 0.019626, acc.: 98.44%] [G loss: 5.154498]\n",
            "9000 [D loss: 0.000140, acc.: 100.00%] [G loss: 4.049295]\n",
            "10000 [D loss: 0.012385, acc.: 100.00%] [G loss: 6.958999]\n",
            "11000 [D loss: 0.000011, acc.: 100.00%] [G loss: 8.708253]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pEOMJswpwg_"
      },
      "source": [
        "classes = {'red' : 0, 'green' : 1, 'blue' : 2, 'bird' : 3, 'combat' : 4, 'dargon' : 5, 'electricity' : 6, 'ghost' : 7, 'insect' : 8, 'normal' : 9\n",
        "         , 'poison' : 10, 'rock' : 11, 'supernatural' : 12, 'ground' : 13, 'ice': 14}"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_VQiBy5fi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}