{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOC00xZGciw2KPRD5piDV1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaos44/CGAN/blob/master/pokemon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbaLrq5OeWPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.compat.v1.keras.layers import BatchNormalization\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import (Activation, Concatenate, Dense,\n",
        "                          Embedding, Flatten, Input, Multiply, Reshape)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcboI0cCeed-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 3\n",
        "\n",
        "#   入力画像の次元\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# 生成器の入力として用いるノイズベクトルのサイズ\n",
        "z_dim = 100\n",
        "\n",
        "# データセットに含まれるクラスの数\n",
        "num_classes = 9"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0wycNQEeiLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator\n",
        "def build_generator(z_dim):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 入力を、全結合層を通じて7 * 7 * 256のテンソルに変形する\n",
        "    ## Denseは入力をテンソルに変えることもできる、第一層だけ、input_dimを指定する必要がある。(input_dimもテンソル指定できるのか、普通はベクトル単位だと思うが)\n",
        "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
        "    ## Reshapeの意味？\n",
        "    model.add(Reshape((7, 7, 256))) \n",
        "\n",
        "    # 転置畳み込み層 from 7x7x256 into 14x14x128 tensor\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ODHKQpbejxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cgan_generator(z_dim):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "    print('num_classes')\n",
        "    print(num_classes)\n",
        "    print()\n",
        "    # Conditioning label: integer 0-9 specifying the number G should generate\n",
        "    label = Input(shape=(1, ), dtype='int32')\n",
        "    print('z:')\n",
        "    print(z)\n",
        "    print()\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # ラベルをz_dimサイズの密のベクトルに変換する。\n",
        "    # 形状(batch_size, 1, z_dim)の3Dテンソルを作成する\n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
        "    print('3D:')\n",
        "    print(label_embedding)\n",
        "    print()\n",
        "    # 3Dテンソルを2Dテンソルに平坦化 (batch_size, z_dim)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print('2D:')\n",
        "    print(label_embedding)\n",
        "    print()\n",
        "    # ノイズz(1, z_dim)? と (batch_size, z_dim)要素ごとの積を取る（ラベルの特徴を持つノイズ） \n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    # print(joined_representation)\n",
        "    generator = build_generator(z_dim)\n",
        "\n",
        "    # 与えられたラベルの画像を生成する\n",
        "    conditioned_img = generator(joined_representation)\n",
        "    # [z, label]も返す意味は？\n",
        "    return Model([z, label], conditioned_img)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFmXUEXMm8KC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "abccc5d3-02fa-4789-f52c-c053b487d521"
      },
      "source": [
        "'''\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "X_train = X_train / 127.5 - 1.\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "# idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "idx = 0\n",
        "imgs, labels = X_train[idx], y_train[idx]\n",
        "\n",
        "print('idx:')\n",
        "print(idx)\n",
        "print()\n",
        "print('imgs:')\n",
        "print(imgs)\n",
        "print()\n",
        "print('labels:')\n",
        "print(labels)\n",
        "print()\n",
        "\n",
        "batch_size = 32\n",
        "generator = build_cgan_generator(z_dim)\n",
        "z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "gen_imgs = generator.predict([z, labels])\n",
        "print(gen_imgs)\n",
        "'''"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n(X_train, y_train), (_, _) = mnist.load_data()\\n\\n# Rescale [0, 255] grayscale pixel values to [-1, 1]\\nX_train = X_train / 127.5 - 1.\\nX_train = np.expand_dims(X_train, axis=3)\\n# idx = np.random.randint(0, X_train.shape[0], batch_size)\\nidx = 0\\nimgs, labels = X_train[idx], y_train[idx]\\n\\nprint('idx:')\\nprint(idx)\\nprint()\\nprint('imgs:')\\nprint(imgs)\\nprint()\\nprint('labels:')\\nprint(labels)\\nprint()\\n\\nbatch_size = 32\\ngenerator = build_cgan_generator(z_dim)\\nz = np.random.normal(0, 1, (batch_size, z_dim))\\ngen_imgs = generator.predict([z, labels])\\nprint(gen_imgs)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnL5E1-BemEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator\n",
        "def build_discriminator(img_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layer, from 28x28x2 into 14x14x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 1),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               input_shape=(img_shape[0], img_shape[1], img_shape[2] + 3),\n",
        "               padding='same'))\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 14x14x64 into 7x7x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
        "    model.add(\n",
        "        Conv2D(128,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Output layer with sigmoid activation\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6tErBu-z2Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 実験コード\n",
        "# 識別器の複合表現 (画像 + ラベル + 画像 + ラベル) 28 * 28 * 4 "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMS5kHcpepkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cgan_discriminator(img_shape):\n",
        "    print(num_classes)\n",
        "    # Input image\n",
        "    img = Input(shape=img_shape)\n",
        "\n",
        "    # Label for the input image\n",
        "    label = Input(shape=(1, ), dtype='int32')\n",
        "\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # Turns labels into dense vectors of size z_dim\n",
        "    # Produces 3D tensor with shape (batch_size, 1, 28*28*1)\n",
        "    label_embedding = Embedding(num_classes,\n",
        "                                np.prod(img_shape),\n",
        "                                input_length=1)(label)\n",
        "  \n",
        "    # Flatten the embedding 3D tensor into 2D tensor with shape (batch_size, 28*28*1)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print(label_embedding)\n",
        "    # Reshape label embeddings to have same dimensions as input images\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    print(label_embedding)\n",
        "    print(img)\n",
        "    # Concatenate images with their label embeddings\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    # concatenated = Multiply()([img, label_embedding]) # Multiply()使うとshapeは(None, 28, 28, 1)でエラー、(None, 28, 28, 2)だと正しい\n",
        "    # 疑問：なぜconcatenatedは(None, 28, 28, 2)のshapeを持たないといけない？\n",
        "    concatenated_tmp = Concatenate(axis=-1)([img, label_embedding])\n",
        "    concatenated = Concatenate(axis=-1)([concatenated_tmp, concatenated_tmp])\n",
        "    print('concatenated:')\n",
        "    print(concatenated)\n",
        "    print()\n",
        "    discriminator = build_discriminator(img_shape)\n",
        "\n",
        "    # Classify the image-label pair\n",
        "    classification = discriminator(concatenated)\n",
        "    # classificationは与えられた\n",
        "    return Model([img, label], classification)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWLSpZJerZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the Model\n",
        "def build_cgan(generator, discriminator):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "\n",
        "    # Image label\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Generated image for that label\n",
        "    img = generator([z, label])\n",
        "\n",
        "    classification = discriminator([img, label])\n",
        "\n",
        "    # Combined Generator -> Discriminator model\n",
        "    # G([z, lablel]) = x*\n",
        "    # D(x*) = classification\n",
        "    model = Model([z, label], classification)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV58o3K9esuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "76414d22-393b-4c60-92d4-2bb6258dd7b9"
      },
      "source": [
        "# Build and compile the Discriminator\n",
        "discriminator = build_cgan_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Build the Generator\n",
        "generator = build_cgan_generator(z_dim)\n",
        "\n",
        "# Keep Discriminator’s parameters constant for Generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build and compile CGAN model with fixed Discriminator to train the Generator\n",
        "cgan = build_cgan(generator, discriminator)\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "Tensor(\"flatten_2/Reshape:0\", shape=(None, 784), dtype=float32)\n",
            "Tensor(\"reshape_1/Reshape:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
            "Tensor(\"input_3:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
            "concatenated:\n",
            "Tensor(\"concatenate_3/concat:0\", shape=(None, 28, 28, 4), dtype=float32)\n",
            "\n",
            "num_classes\n",
            "9\n",
            "\n",
            "z:\n",
            "Tensor(\"input_5:0\", shape=(None, 100), dtype=float32)\n",
            "\n",
            "3D:\n",
            "Tensor(\"embedding_2/embedding_lookup/Identity_1:0\", shape=(None, 1, 100), dtype=float32)\n",
            "\n",
            "2D:\n",
            "Tensor(\"flatten_4/Reshape:0\", shape=(None, 100), dtype=float32)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZTeGuQPRkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import re"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLJD98seuO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "\n",
        "    # Load the MNIST dataset\n",
        "    # (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    # 画像の読み込みとnumpy配列への変換\n",
        "    X_train = [] # リスト\n",
        "    y_train = [] # リスト\n",
        "    photos_dir = './img'  \n",
        "    files = glob.glob(photos_dir + '/*.png')\n",
        "    for i, file in enumerate(files):\n",
        "        label = re.search(r'\\/([^\\/]+)_', file).groups()[0]\n",
        "        image = Image.open(file)\n",
        "        image = image.convert('RGB')\n",
        "        image = image.resize((img_rows, img_cols))\n",
        "        data = np.asarray(image, dtype=np.float32)\n",
        "        X_train.append(data)\n",
        "        y_train.append(label)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the Discriminator\n",
        "        # -------------------------\n",
        "\n",
        "        # Get a random batch of real images and their labels\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        print(imgs, labels)\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "        # Train the Discriminator\n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of noise vectors\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "        # Get a batch of random labels\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "\n",
        "        # Train the Generator\n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "\n",
        "        if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            # Output training progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (iteration + 1, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "\n",
        "            # Save losses and accuracies so they can be plotted after training\n",
        "            losses.append((d_loss[0], g_loss))\n",
        "            accuracies.append(100 * d_loss[1])\n",
        "\n",
        "            # Output sample of generated images\n",
        "            sample_images()"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFZPbM6evwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-9\n",
        "    labels = np.arange(0, 10).reshape(-1, 1)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Digit: %d\" % labels[cnt])\n",
        "            cnt += 1"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R69fobc4exPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a1b7d33-4ea5-48fe-e558-ea1382a5dcef"
      },
      "source": [
        "# Train the Model and Inspect Training Progres\n",
        "# Note that the 'Discrepancy between trainable weights and collected trainable' warning from Keras is expected. \n",
        "# It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa.\n",
        "\n",
        "# Set hyperparameters\n",
        "iterations = 12000\n",
        "batch_size = 32\n",
        "sample_interval = 1000\n",
        "\n",
        "# Train the CGAN for the specified number of iterations\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-0.09019607 -0.44313723 -0.56078434]]\n",
            "\n",
            "   [[ 0.48235297 -0.06666666 -0.25490195]]\n",
            "\n",
            "   [[-0.23137254 -0.6156863  -0.7411765 ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[ 0.5294118  -0.19999999 -0.44313723]]\n",
            "\n",
            "   [[ 1.          0.04313731 -0.27843136]]\n",
            "\n",
            "   [[ 1.          0.0196079  -0.30196077]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]]\n",
            "\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            "\n",
            " [[[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-0.45098037 -0.25490195 -0.6862745 ]]\n",
            "\n",
            "   [[-0.9372549  -0.92156863 -0.9607843 ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-0.24705881  0.01176476 -0.56078434]]\n",
            "\n",
            "   [[-0.92156863 -0.8980392  -0.94509804]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-0.92156863 -0.8980392  -0.94509804]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-0.7882353  -0.78039217 -0.7882353 ]]\n",
            "\n",
            "   [[-0.9607843  -0.9607843  -0.9607843 ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  ...\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            "  [[[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]\n",
            "\n",
            "   [[-1.         -1.         -1.        ]]]]] ['blue' 'bird' 'insect' 'insect' 'bird' 'bird' 'bird' 'insect' 'insect'\n",
            " 'green' 'poison' 'insect' 'electricity' 'insect' 'insect' 'electricity'\n",
            " 'bird' 'insect' 'insect' 'bird' 'red' 'bird' 'red' 'electricity' 'red'\n",
            " 'green' 'red' 'insect' 'red' 'electricity' 'insect' 'insect']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-fb01a0380fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the CGAN for the specified number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-113-1984730a7f0f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Generate a batch of fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Train the Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to int32 is not supported\n\t [[node functional_3/Cast (defined at <ipython-input-95-2d949fb714f2>:48) ]] [Op:__inference_predict_function_1760]\n\nFunction call stack:\npredict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg7i6q-reyox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QiC4mgFHLPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}