{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhlpT/04rJZ0AidmgfdcGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaos44/CGAN/blob/master/pokemon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbaLrq5OeWPL"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.compat.v1.keras.layers import BatchNormalization\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import (Activation, Concatenate, Dense,\n",
        "                          Embedding, Flatten, Input, Multiply, Reshape)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPPENm6mvmy"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)#2. Get the file\n",
        "pokemon = drive.CreateFile({'id':'1E41YoGi2qBFsT5wijnPT9xm0Y8BFB1bz'}) # replace the id with id of file you want to access\n",
        "pokemon.GetContentFile('pokemon.zip')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqRPsao7nOcD"
      },
      "source": [
        "!unzip pokemon.zip -d pokemon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebaDL-qbDYsi"
      },
      "source": [
        "# パラメータの初期化\n",
        "classes = {'red' : 0, 'green' : 1, 'blue' : 2, 'bird' : 3, 'combat' : 4, 'dargon' : 5, 'electricity' : 6, 'ghost' : 7, 'insect' : 8, 'normal' : 9\n",
        "         , 'poison' : 10, 'rock' : 11, 'supernatural' : 12, 'ground' : 13, 'ice': 14}"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcboI0cCeed-"
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 3\n",
        "\n",
        "#   入力画像の次元\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# 生成器の入力として用いるノイズベクトルのサイズ\n",
        "z_dim = 100\n",
        "\n",
        "# データセットに含まれるクラスの数\n",
        "num_classes = 14"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0wycNQEeiLM"
      },
      "source": [
        "# Generator\n",
        "def build_generator(z_dim):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 入力を、全結合層を通じて7 * 7 * 256のテンソルに変形する\n",
        "    ## Denseは入力をテンソルに変えることもできる、第一層だけ、input_dimを指定する必要がある。(input_dimもテンソル指定できるのか、普通はベクトル単位だと思うが)\n",
        "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
        "    ## Reshapeの意味？\n",
        "    model.add(Reshape((7, 7, 256))) \n",
        "\n",
        "    # 転置畳み込み層 from 7x7x256 into 14x14x128 tensor\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ODHKQpbejxd"
      },
      "source": [
        "def build_cgan_generator(z_dim):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "    print('num_classes')\n",
        "    print(num_classes)\n",
        "    print()\n",
        "    # Conditioning label: integer 0-9 specifying the number G should generate\n",
        "    label = Input(shape=(1, ))\n",
        "    print('z:')\n",
        "    print(z)\n",
        "    print()\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # ラベルをz_dimサイズの密のベクトルに変換する。\n",
        "    # 形状(batch_size, 1, z_dim)の3Dテンソルを作成する\n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
        "    print('3D:')\n",
        "    print(label_embedding)\n",
        "    print()\n",
        "    # 3Dテンソルを2Dテンソルに平坦化 (batch_size, z_dim)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print('2D:')\n",
        "    print(label_embedding)\n",
        "    print()\n",
        "    # ノイズz(1, z_dim)? と (batch_size, z_dim)要素ごとの積を取る（ラベルの特徴を持つノイズ） \n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    # print(joined_representation)\n",
        "    generator = build_generator(z_dim)\n",
        "\n",
        "    # 与えられたラベルの画像を生成する\n",
        "    conditioned_img = generator(joined_representation)\n",
        "    # [z, label]も返す意味は？\n",
        "    return Model([z, label], conditioned_img)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFmXUEXMm8KC",
        "outputId": "ddaf0a98-e691-4438-e187-8417d1710c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "'''\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "X_train = X_train / 127.5 - 1.\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "# idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "idx = 0\n",
        "imgs, labels = X_train[idx], y_train[idx]\n",
        "\n",
        "print('idx:')\n",
        "print(idx)\n",
        "print()\n",
        "print('imgs:')\n",
        "print(imgs)\n",
        "print()\n",
        "print('labels:')\n",
        "print(labels)\n",
        "print()\n",
        "\n",
        "batch_size = 32\n",
        "generator = build_cgan_generator(z_dim)\n",
        "z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "gen_imgs = generator.predict([z, labels])\n",
        "print(gen_imgs)\n",
        "'''"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n(X_train, y_train), (_, _) = mnist.load_data()\\n\\n# Rescale [0, 255] grayscale pixel values to [-1, 1]\\nX_train = X_train / 127.5 - 1.\\nX_train = np.expand_dims(X_train, axis=3)\\n# idx = np.random.randint(0, X_train.shape[0], batch_size)\\nidx = 0\\nimgs, labels = X_train[idx], y_train[idx]\\n\\nprint('idx:')\\nprint(idx)\\nprint()\\nprint('imgs:')\\nprint(imgs)\\nprint()\\nprint('labels:')\\nprint(labels)\\nprint()\\n\\nbatch_size = 32\\ngenerator = build_cgan_generator(z_dim)\\nz = np.random.normal(0, 1, (batch_size, z_dim))\\ngen_imgs = generator.predict([z, labels])\\nprint(gen_imgs)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnL5E1-BemEt"
      },
      "source": [
        "# Discriminator\n",
        "def build_discriminator(img_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layer, from 28x28x2 into 14x14x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 3),\n",
        "               # チャンネル数も加算\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 4),\n",
        "               padding='same'))\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 14x14x64 into 7x7x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
        "    model.add(\n",
        "        Conv2D(128,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Output layer with sigmoid activation\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6tErBu-z2Cr"
      },
      "source": [
        "# 実験コード\n",
        "# 識別器の複合表現 (画像 + ラベル + 画像 + ラベル) 28 * 28 * 4 "
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMS5kHcpepkY"
      },
      "source": [
        "def build_cgan_discriminator(img_shape):\n",
        "    print(num_classes)\n",
        "    # Input image\n",
        "    img = Input(shape=img_shape)\n",
        "\n",
        "    # Label for the input image\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # Turns labels into dense vectors of size z_dim\n",
        "    # Produces 3D tensor with shape (batch_size, 1, 28*28*1)\n",
        "    label_embedding = Embedding(num_classes,\n",
        "                                np.prod(img_shape),\n",
        "                                input_length=1)(label)\n",
        "  \n",
        "    # Flatten the embedding 3D tensor into 2D tensor with shape (batch_size, 28*28*1)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print(label_embedding)\n",
        "    # Reshape label embeddings to have same dimensions as input images\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    print(label_embedding)\n",
        "    print(img)\n",
        "    # Concatenate images with their label embeddings\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    concatenated = Multiply()([img, label_embedding]) # Multiply()使うとshapeは(None, 28, 28, 1)でエラー、(None, 28, 28, 2)だと正しい\n",
        "    # 疑問：なぜconcatenatedは(None, 28, 28, 2)のshapeを持たないといけない？\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    # concatenated = Concatenate(axis=-1)([concatenated_tmp, concatenated_tmp])\n",
        "    print('concatenated:')\n",
        "    print(concatenated)\n",
        "    print()\n",
        "    discriminator = build_discriminator(img_shape)\n",
        "\n",
        "    # Classify the image-label pair\n",
        "    classification = discriminator(concatenated)\n",
        "    # classificationは与えられた\n",
        "    return Model([img, label], classification)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWLSpZJerZ-"
      },
      "source": [
        "# Build the Model\n",
        "def build_cgan(generator, discriminator):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "\n",
        "    # Image label\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Generated image for that label\n",
        "    img = generator([z, label])\n",
        "\n",
        "    classification = discriminator([img, label])\n",
        "\n",
        "    # Combined Generator -> Discriminator model\n",
        "    # G([z, lablel]) = x*\n",
        "    # D(x*) = classification\n",
        "    model = Model([z, label], classification)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV58o3K9esuV",
        "outputId": "f9f7f72a-c1a6-49ba-b048-a92e4d3811a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# Build and compile the Discriminator\n",
        "discriminator = build_cgan_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Build the Generator\n",
        "generator = build_cgan_generator(z_dim)\n",
        "\n",
        "# Keep Discriminator’s parameters constant for Generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build and compile CGAN model with fixed Discriminator to train the Generator\n",
        "cgan = build_cgan(generator, discriminator)\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "Tensor(\"flatten_40/Reshape:0\", shape=(None, 2352), dtype=float32)\n",
            "Tensor(\"reshape_24/Reshape:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
            "Tensor(\"input_61:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
            "concatenated:\n",
            "Tensor(\"multiply_10/mul:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
            "\n",
            "num_classes\n",
            "14\n",
            "\n",
            "z:\n",
            "Tensor(\"input_63:0\", shape=(None, 100), dtype=float32)\n",
            "\n",
            "3D:\n",
            "Tensor(\"embedding_25/embedding_lookup/Identity_1:0\", shape=(None, 1, 100), dtype=float32)\n",
            "\n",
            "2D:\n",
            "Tensor(\"flatten_42/Reshape:0\", shape=(None, 100), dtype=float32)\n",
            "\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 3) for input Tensor(\"input_61:0\", shape=(None, 28, 28, 3), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZTeGuQPRkH"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import re"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLJD98seuO2"
      },
      "source": [
        "# Training\n",
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "\n",
        "    # Load the MNIST dataset\n",
        "    # (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    # 画像の読み込みとnumpy配列への変換\n",
        "    X_train = [] # リスト\n",
        "    y_train = [] # リスト\n",
        "    photos_dir = './pokemon'  \n",
        "    files = glob.glob(photos_dir + '/*.png')\n",
        "    for i, file in enumerate(files):\n",
        "        label = re.search(r'\\/([^\\/]+)_', file).groups()[0]\n",
        "        image = Image.open(file)\n",
        "        image = image.convert('RGB')\n",
        "        image = image.resize((img_rows, img_cols))\n",
        "        data = np.asarray(image, dtype=np.float32)\n",
        "        X_train.append(data)\n",
        "        y_train.append(classes[label])\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the Discriminator\n",
        "        # -------------------------\n",
        "\n",
        "        # Get a random batch of real images and their labels\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        print('test:', labels)\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "        # Train the Discriminator\n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of noise vectors\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "        # Get a batch of random labels\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        print('labels : ', labels)\n",
        "        # Train the Generator\n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "\n",
        "        if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            # Output training progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (iteration + 1, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "\n",
        "            # Save losses and accuracies so they can be plotted after training\n",
        "            losses.append((d_loss[0], g_loss))\n",
        "            accuracies.append(100 * d_loss[1])\n",
        "\n",
        "            # Output sample of generated images\n",
        "            sample_images()"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFZPbM6evwH"
      },
      "source": [
        "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-9\n",
        "    labels = np.arange(0, 10).reshape(-1, 1)\n",
        "    print('labels:', labels)\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Digit: %d\" % labels[cnt])\n",
        "            cnt += 1"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R69fobc4exPF",
        "outputId": "4b4e782a-1ad7-4099-f332-a75a150701b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the Model and Inspect Training Progres\n",
        "# Note that the 'Discrepancy between trainable weights and collected trainable' warning from Keras is expected. \n",
        "# It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa.\n",
        "\n",
        "# Set hyperparameters\n",
        "iterations = 12000\n",
        "batch_size = 32\n",
        "sample_interval = 1000\n",
        "\n",
        "# Train the CGAN for the specified number of iterations\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test: [ 6  2  9  9 10  7  9  7  9  0  9 11  3  2  8  2 13 11 12  5  7  2 11  2\n",
            "  2 13  0  0  8  3  4 10]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 3) for input Tensor(\"input_61:0\", shape=(None, 28, 28, 3), dtype=float32), but it was called on an input with incompatible shape (32, 28, 28, 1, 3).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-fb01a0380fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the CGAN for the specified number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-186-a96ec7a3eb23>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Train the Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:183 call\n        return self._merge_function(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py:322 _merge_function\n        output *= inputs[i]\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1141 binary_op_wrapper\n        raise e\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1125 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1457 _mul_dispatch\n        return multiply(x, y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:509 multiply\n        return gen_math_ops.mul(x, y, name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:6176 mul\n        \"Mul\", x=x, y=y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 28 and 32 for '{{node functional_29/multiply_10/mul}} = Mul[T=DT_FLOAT](IteratorGetNext, functional_29/reshape_24/Reshape)' with input shapes: [32,28,28,1,3], [32,28,28,3].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg7i6q-reyox"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QiC4mgFHLPI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}