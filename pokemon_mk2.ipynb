{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbDrA3BwYlZ+feaTtROoZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaos44/CGAN/blob/master/pokemon_mk2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbaLrq5OeWPL"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.compat.v1.keras.layers import BatchNormalization\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import (Activation, Concatenate, Dense,\n",
        "                          Embedding, Flatten, Input, Multiply, Reshape)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPPENm6mvmy"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)#2. Get the file\n",
        "pokemon = drive.CreateFile({'id':'1_46S-S6vVrv0VzEUeKvoJfsTUUiohtTR'}) # replace the id with id of file you want to access\n",
        "pokemon.GetContentFile('pokemon_mk2.zip')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqRPsao7nOcD",
        "outputId": "a93fffca-b5c9-41d6-9803-ffa33250dce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip pokemon_mk2.zip"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  pokemon_mk2.zip\n",
            " extracting: pokemon_mk2/bird_1.png  \n",
            "  inflating: pokemon_mk2/pikachu_ (2).png  \n",
            " extracting: pokemon_mk2/pikachu_ (3).png  \n",
            " extracting: pokemon_mk2/pikachu_.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (10) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (10).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (11) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (11).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (12) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (12).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (13) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (13).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (14) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (14).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (15) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (15).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (16) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (16).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (17) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (17).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (18) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (18).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (19) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (19).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (2) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (2).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (20) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (20).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (21) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (21).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (22) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (22).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (23) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (23).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (24) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (24).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (25) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (25).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (26) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (26).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (27) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (27).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (28) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (28).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (29) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (29).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (3) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (3).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (30) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (30).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (31) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (31).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (32) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (32).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (33) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (33).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (34) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (34).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (35) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (35).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (36) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (36).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (37) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (37).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (38) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (38).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (39) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (39).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (4) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (4).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (40) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (40).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (41) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (42) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (43) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (44) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (45) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (46) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (47) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (48) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (49) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (5) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (5).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (50) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (51) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (52) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (53) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (54) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (55) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (56) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (57) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (58) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (59) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (6) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (6).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (60) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (61) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (62) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (63) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (64) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (65) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (66) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (67) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (68) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (69) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (7) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (7).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (70) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (71) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (72) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (73) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (74) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (75) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (76) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (77) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (78) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (79) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (8) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (8).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (80) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (81) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (82) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (83) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (84) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (85) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (86) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (87) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (88) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (89) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (9) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (9).png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (90) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (91) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (92) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (93) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (94) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[ (95) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1 - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_1.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (10) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (11) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (12) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (13) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (14) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (15) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (16) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (17) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (18) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (19) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (2) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (2) - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (2).png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (20) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (3) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (4) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (5) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (6) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (7) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (8) - ГRГsБ[ - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/pikachu_2 (9) - ГRГsБ[ - ГRГsБ[.png  \n",
            " extracting: pokemon_mk2/pikachu_2.png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[ (2).png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[ (3).png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[ (4).png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[ (5).png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[ (6).png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[ (7).png  \n",
            " extracting: pokemon_mk2/popo - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/popo_2.png  \n",
            "  inflating: pokemon_mk2/popo_3 - ГRГsБ[.png  \n",
            "  inflating: pokemon_mk2/popo_3.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebaDL-qbDYsi"
      },
      "source": [
        "# パラメータの初期化\n",
        "classes = {'pikachu' : 0, 'popo' : 1}"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcboI0cCeed-"
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 3\n",
        "\n",
        "#   入力画像の次元\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# 生成器の入力として用いるノイズベクトルのサイズ\n",
        "z_dim = 1024\n",
        "\n",
        "# データセットに含まれるクラスの数\n",
        "num_classes = 2"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0wycNQEeiLM"
      },
      "source": [
        "# Generator\n",
        "def build_generator(z_dim):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 入力を、全結合層を通じて7 * 7 * 256のテンソルに変形する\n",
        "    ## Denseは入力をテンソルに変えることもできる、第一層だけ、input_dimを指定する必要がある。(input_dimもテンソル指定できるのか、普通はベクトル単位だと思うが)\n",
        "    model.add(Dense(512 * 7 * 7, input_dim=z_dim))\n",
        "    ## Reshapeの意味？\n",
        "    model.add(Reshape((7, 7, 512))) \n",
        "    # 転置畳み込み層 from 7x7x256 into 14x14x256 tensor\n",
        "    model.add(Conv2DTranspose(256, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "    model.add(Conv2DTranspose(32, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "    model.add(Conv2DTranspose(channels, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ODHKQpbejxd"
      },
      "source": [
        "def build_cgan_generator(z_dim):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "    print('num_classes')\n",
        "    print(num_classes)\n",
        "    print()\n",
        "    # Conditioning label: integer 0-9 specifying the number G should generate\n",
        "    label = Input(shape=(1, ))\n",
        "    print('z:')\n",
        "    print(z)\n",
        "    print()\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # ラベルをz_dimサイズの密のベクトルに変換する。\n",
        "    # 形状(batch_size, 1, z_dim)の3Dテンソルを作成する\n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
        "    print('3D:')\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    print()\n",
        "    # 3Dテンソルを2Dテンソルに平坦化 (batch_size, z_dim)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print('2D:')\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    print()\n",
        "    # ノイズz(1, z_dim)? と (batch_size, z_dim)要素ごとの積を取る（ラベルの特徴を持つノイズ） \n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    print(joined_representation)\n",
        "    print(joined_representation.shape)\n",
        "    generator = build_generator(z_dim)\n",
        "\n",
        "    # 与えられたラベルの画像を生成する\n",
        "    conditioned_img = generator(joined_representation)\n",
        "    # [z, label]も返す意味は？\n",
        "    return Model([z, label], conditioned_img)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFmXUEXMm8KC",
        "outputId": "6c4d8507-4a1c-485c-a8a6-821a61049796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "'''\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "X_train = X_train / 127.5 - 1.\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "# idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "idx = 0\n",
        "imgs, labels = X_train[idx], y_train[idx]\n",
        "\n",
        "print('idx:')\n",
        "print(idx)\n",
        "print()\n",
        "print('imgs:')\n",
        "print(imgs)\n",
        "print()\n",
        "print('labels:')\n",
        "print(labels)\n",
        "print()\n",
        "\n",
        "batch_size = 32\n",
        "generator = build_cgan_generator(z_dim)\n",
        "z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "gen_imgs = generator.predict([z, labels])\n",
        "print(gen_imgs)\n",
        "'''"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n(X_train, y_train), (_, _) = mnist.load_data()\\n\\n# Rescale [0, 255] grayscale pixel values to [-1, 1]\\nX_train = X_train / 127.5 - 1.\\nX_train = np.expand_dims(X_train, axis=3)\\n# idx = np.random.randint(0, X_train.shape[0], batch_size)\\nidx = 0\\nimgs, labels = X_train[idx], y_train[idx]\\n\\nprint('idx:')\\nprint(idx)\\nprint()\\nprint('imgs:')\\nprint(imgs)\\nprint()\\nprint('labels:')\\nprint(labels)\\nprint()\\n\\nbatch_size = 32\\ngenerator = build_cgan_generator(z_dim)\\nz = np.random.normal(0, 1, (batch_size, z_dim))\\ngen_imgs = generator.predict([z, labels])\\nprint(gen_imgs)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnL5E1-BemEt"
      },
      "source": [
        "# Discriminator\n",
        "def build_discriminator(img_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layer, from 28x28x2 into 14x14x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2]),\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 3),\n",
        "               # チャンネル数も加算\n",
        "               # input_shape=(img_shape[0], img_shape[1], img_shape[2] + 4),\n",
        "               padding='same'))\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 14x14x64 into 7x7x64 tensor\n",
        "    model.add(\n",
        "        Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
        "    model.add(\n",
        "        Conv2D(128,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Output layer with sigmoid activation\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6tErBu-z2Cr"
      },
      "source": [
        "# 実験コード\n",
        "# 識別器の複合表現 (画像 + ラベル + 画像 + ラベル) 28 * 28 * 4 "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMS5kHcpepkY"
      },
      "source": [
        "def build_cgan_discriminator(img_shape):\n",
        "    print(num_classes)\n",
        "    # Input image\n",
        "    img = Input(shape=img_shape)\n",
        "\n",
        "    # Label for the input image\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Label embedding:\n",
        "    # ----------------\n",
        "    # Turns labels into dense vectors of size z_dim\n",
        "    # Produces 3D tensor with shape (batch_size, 1, 28*28*1)\n",
        "    label_embedding = Embedding(num_classes,\n",
        "                                np.prod(img_shape),\n",
        "                                input_length=1)(label)\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    # Flatten the embedding 3D tensor into 2D tensor with shape (batch_size, 28*28*1)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    print(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    # Reshape label embeddings to have same dimensions as input images\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    print(label_embedding.shape)\n",
        "    print(img.shape)\n",
        "    # Concatenate images with their label embeddings\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    concatenated = Multiply()([img, label_embedding]) # Multiply()使うとshapeは(None, 28, 28, 1)でエラー、(None, 28, 28, 2)だと正しい\n",
        "    # 疑問：なぜconcatenatedは(None, 28, 28, 2)のshapeを持たないといけない？\n",
        "    # concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    # concatenated = Concatenate(axis=-1)([concatenated_tmp, concatenated_tmp])\n",
        "    print('concatenated:')\n",
        "    print(concatenated)\n",
        "    print(concatenated.shape)\n",
        "    print()\n",
        "    discriminator = build_discriminator(img_shape)\n",
        "\n",
        "    # Classify the image-label pair\n",
        "    classification = discriminator(concatenated)\n",
        "    # classificationは与えられた\n",
        "    return Model([img, label], classification)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWLSpZJerZ-"
      },
      "source": [
        "# Build the Model\n",
        "def build_cgan(generator, discriminator):\n",
        "\n",
        "    # Random noise vector z\n",
        "    z = Input(shape=(z_dim, ))\n",
        "\n",
        "    # Image label\n",
        "    label = Input(shape=(1, ))\n",
        "\n",
        "    # Generated image for that label\n",
        "    img = generator([z, label])\n",
        "\n",
        "    classification = discriminator([img, label])\n",
        "\n",
        "    # Combined Generator -> Discriminator model\n",
        "    # G([z, lablel]) = x*\n",
        "    # D(x*) = classification\n",
        "    model = Model([z, label], classification)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV58o3K9esuV",
        "outputId": "7283762f-afdb-46a9-dc62-3a3254e569db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build and compile the Discriminator\n",
        "discriminator = build_cgan_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "discriminator.summary()\n",
        "# Build the Generator\n",
        "generator = build_cgan_generator(z_dim)\n",
        "generator.summary()\n",
        "# Keep Discriminator’s parameters constant for Generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build and compile CGAN model with fixed Discriminator to train the Generator\n",
        "cgan = build_cgan(generator, discriminator)\n",
        "cgan.summary()\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "Tensor(\"embedding_4/embedding_lookup/Identity_1:0\", shape=(None, 1, 2352), dtype=float32)\n",
            "(None, 1, 2352)\n",
            "Tensor(\"flatten_6/Reshape:0\", shape=(None, 2352), dtype=float32)\n",
            "(None, 2352)\n",
            "(None, 28, 28, 3)\n",
            "(None, 28, 28, 3)\n",
            "concatenated:\n",
            "Tensor(\"multiply_4/mul:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
            "(None, 28, 28, 3)\n",
            "\n",
            "Model: \"functional_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 2352)      4704        input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 2352)         0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           [(None, 28, 28, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 28, 28, 3)    0           flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 28, 28, 3)    0           input_13[0][0]                   \n",
            "                                                                 reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 1)            115393      multiply_4[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 120,097\n",
            "Trainable params: 119,713\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n",
            "num_classes\n",
            "2\n",
            "\n",
            "z:\n",
            "Tensor(\"input_15:0\", shape=(None, 1024), dtype=float32)\n",
            "\n",
            "3D:\n",
            "Tensor(\"embedding_5/embedding_lookup/Identity_1:0\", shape=(None, 1, 1024), dtype=float32)\n",
            "(None, 1, 1024)\n",
            "\n",
            "2D:\n",
            "Tensor(\"flatten_8/Reshape:0\", shape=(None, 1024), dtype=float32)\n",
            "(None, 1024)\n",
            "\n",
            "Tensor(\"multiply_5/mul:0\", shape=(None, 1024), dtype=float32)\n",
            "(None, 1024)\n",
            "Model: \"functional_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 1024)      2048        input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 1024)         0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 1024)         0           input_15[0][0]                   \n",
            "                                                                 flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 28, 28, 3)    27285187    multiply_5[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 27,287,235\n",
            "Trainable params: 27,286,275\n",
            "Non-trainable params: 960\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"functional_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_15 (Functional)      (None, 28, 28, 3)    27287235    input_17[0][0]                   \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_13 (Functional)      (None, 1)            120097      functional_15[0][0]              \n",
            "                                                                 input_18[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 27,407,332\n",
            "Trainable params: 27,286,275\n",
            "Non-trainable params: 121,057\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZTeGuQPRkH"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import re"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqLJD98seuO2"
      },
      "source": [
        "# Training\n",
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "\n",
        "    # Load the MNIST dataset\n",
        "    # (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    # 画像の読み込みとnumpy配列への変換\n",
        "    X_train = [] # リスト\n",
        "    y_train = [] # リスト\n",
        "    photos_dir = './pokemon_mk2'  \n",
        "    files = glob.glob(photos_dir + '/*.png')\n",
        "    for i, file in enumerate(files):\n",
        "        label = re.search(r'\\/([^\\/]+)_', file).groups()[0]\n",
        "        print(label)\n",
        "        image = Image.open(file)\n",
        "        image = image.convert('RGB')\n",
        "        image = image.resize((img_rows, img_cols))\n",
        "        data = np.asarray(image, dtype=np.float32)\n",
        "        X_train.append(data)\n",
        "        y_train.append(classes[label])\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    # X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the Discriminator\n",
        "        # -------------------------\n",
        "\n",
        "        # Get a random batch of real images and their labels\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        # print('test:', labels)\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "        # print('z', z.shape)\n",
        "        # print()\n",
        "        # print('gen_imgs', gen_imgs.shape)\n",
        "        # print()\n",
        "        # print('imgs', imgs.shape)\n",
        "        # print()\n",
        "        # print('labels', labels.shape)\n",
        "        # Train the Discriminator\n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of noise vectors\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "        # Get a batch of random labels\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "\n",
        "        # Train the Generator\n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "\n",
        "        if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            # Output training progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (iteration + 1, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "\n",
        "            # Save losses and accuracies so they can be plotted after training\n",
        "            losses.append((d_loss[0], g_loss))\n",
        "            accuracies.append(100 * d_loss[1])\n",
        "\n",
        "            # Output sample of generated images\n",
        "            sample_images()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFZPbM6evwH"
      },
      "source": [
        "def sample_images(image_grid_rows=1, image_grid_columns=2):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-2\n",
        "    labels = np.arange(0, 2).reshape(-1, 1)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(np.clip(gen_imgs[cnt, :, :, :], 0, 1.)) \n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Digit: %d\" % labels[cnt])\n",
        "            cnt += 1"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R69fobc4exPF",
        "outputId": "574d2e5f-ae1e-49ff-d6ab-9b582f41b684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "# Train the Model and Inspect Training Progres\n",
        "# Note that the 'Discrepancy between trainable weights and collected trainable' warning from Keras is expected. \n",
        "# It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa.\n",
        "\n",
        "# Set hyperparameters\n",
        "iterations = 10000\n",
        "batch_size = 32\n",
        "sample_interval = 1000\n",
        "\n",
        "# Train the CGAN for the specified number of iterations\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pokemon\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-fde48c77bf77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the CGAN for the specified number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-abe9fe97a489>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pokemon'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pEOMJswpwg_"
      },
      "source": [
        "classes = {'red' : 0, 'green' : 1, 'blue' : 2, 'bird' : 3, 'combat' : 4, 'dargon' : 5, 'electricity' : 6, 'ghost' : 7, 'insect' : 8, 'normal' : 9\n",
        "         , 'poison' : 10, 'rock' : 11, 'supernatural' : 12, 'ground' : 13, 'ice': 14}"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_VQiBy5fi5"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}